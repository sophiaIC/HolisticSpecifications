%-------------------------------------------------------------------------
% Marsden 2018 - Full Research Proposal Template - Sections 2A-2E (Standard and Fast-Start)
%-------------------------------------------------------------------------
% This form is designed for A4 paper.
% Please check your settings.
%-------------------------------------------------------------------------
% N.B. Spaces for data entry are marked as follows: xxxxxxx
%-------------------------------------------------------------------------
\documentclass[a4paper,12pt]{article}
\usepackage{amsfonts,amssymb}
\usepackage{ifthen}
\pagestyle{empty}
\setlength{\textwidth}{17.6cm}
\setlength{\oddsidemargin}{-0.8cm}
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%KJX CAPE MARCOS BELOW


\usepackage{url}
\usepackage{setspace}

\usepackage{rotating}
\usepackage{xspace}
\usepackage{enumerate}

% \usepackage[numbers]{natbib}
% \setlength{\bibsep}{0.0pt}
% \renewcommand{\bibsection}{}

\usepackage[sorting=nyt,minnames=3,citestyle=numeric-comp]{biblatex}
\addbibresource{Case.bib}
\setlength{\bibitemsep}{2pt}

\renewcommand*{\mkbibnamegiven}[1]{%
  \ifitemannotation{grant}
    {\textbf{#1}}
    {#1}}
\renewcommand*{\mkbibnamefamily}[1]{%
  \ifitemannotation{grant}
    {\textbf{#1}}
    {#1}}

\usepackage{microtype}

\newcommand{\forget}[1]{} % {{#1}}
\pagestyle{empty}

\newcommand{\etc}{{\it etc.}}
\newcommand{\eg}{{\it e.g.\,}}
\newcommand{\ie}{{\it i.e.\,}}
\newcommand{\rely}{{rely}}
\newcommand{\Rely}{{Rely}}
\newcommand{\deny}{{deny}}
\newcommand{\Deny}{{Deny}}

\usepackage[usenames]{color}
\input{macrosOCRA}

\usepackage{latexsym}
\usepackage{listings}
\usepackage{times}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\newcommand{\sparagraph}[1]{{ \vspace{.05in} \noindent {\bf {#1}}}}
\newcommand{\sd}[1]{#1} % {{\color{red}{#1}}}
\newcommand{\jn}[1]{#1} % {{\color{green}{#1}}}




\lstset{ %
  language=Java,                % the language of the code
  basicstyle=\small\sffamily,           % the size of the fonts that are used for the code
  keywordstyle=\small\color{blue}\sffamily,          % keyword style
  commentstyle=\color{gray}\itshape,       % comment style
  stringstyle=\color{mauve}\ttfamily,         % string literal style
  columns=flexible,
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{dkgreen},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two
                                % line-numbers. If it's 1, each line
                                  % will be numbered
  firstnumber=last,
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                   % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  escapechar={\%},            % if you want to add LaTeX within your
                              % code
  %morekeywords={},
  keywords={private,public,final,this,throw,new,||,&&,to,def,any,method,rely,deny,without,unless,specification,if,then,var,is,readable,writeable,owned,some,outside,pre,post,assume,assert}               % if you want to add more keywords to the set
}


%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
\setlength{\textheight}{26.6cm} \setlength{\topmargin}{-2.1cm}
%-----------------------------------------------------------------------
% \newlist macro for publication lists - adds a \goodbreak so as
% not to leave a section header at a page bottom
%------------------------------------------------------------------------
\def\newlist#1{\goodbreak\noindent{\bf#1}\vskip-6pt\nobreak}

%-------------------------------------------------------------------------
\begin{document}
%----------------------------------------------------------------------

%----------------------------------------------------------------------
\noindent {\bf 2A.   BACKGROUND} \\
%----------------------------------------------------------------------
%{\tiny \\ {\scriptsize Use this section to give a context for the
%proposal by summarising in plain English the state of knowledge in
%the field. {\bf  Please use a MAXIMUM of 6 pages for sections 2A-2D
%combined if you have tickerd one or more Vision M\=atauranga themes
%in section 3, or a maximum of 5 pages for 2A-2C combined if you have
%ticked N/A in section 3.} These instructions should be removed;
%please do not change the margins.}\par} 
%----------------------------------------------------------------------
% ENTER the Background to the proposal.
%----------------------------------------------------------------------
%
%
%\begin{spacing}{0.99}
Software guards our secrets \cite{covfefe}.  As more personal and
corporate information moves onto the Internet, security breaches can
end careers, win elections, and cost hundreds of millions of dollars.
%
{\em Object Capabilities} \cite{MillerPhD} are programming
constructs
that can help programs maintain security, % and robustness
even in an ``open world'' where they interact with external,
untrusted programs of unknown provenance
\cite{membranesJavascript,miller-esop2013,ecma,JoeE,Pony}.  
%FROM 2013 APPN:
A capability is an unforgeable key that provides access to system
services and resources. A program is permitted to invoke a service or
consume a resource only if it possesses the capability for that
service or resource \cite{Dennis66,Lampson76,CAP,Hardy88}. An
object-capability system 
%
%brings traditional capability security to
%object-oriented programming languages by 
treats individual
objects in a program as capabilities \cite{MillerPhD}. 
% This ensures
% that capabilities (references to objects) can only be acquired by
% interacting with other objects that possess the desired capabilities.
Object references cannot be forged (new capabilities always refer to
newly created objects, not pre{\"e}xisting objects), cannot be
acquired indirectly (e.g.\ there are no global variables are accessible to
many different objects) or covertly (e.g.\ access modifiers cannot be 
bypassed by reflection).

%ENDFROM
Recent programming languages and web systems
\cite{CapJavaHayesAPLAS17,CapNetSocc17Eide,DOCaT14} including Newspeak
\cite{newspeak17}, Dart \cite{dart15}, Grace \cite{grace,graceClasses}
and Wyvern \cite{wyverncapabilities} have adopted the object
capability model.
%
%
Object capabilities' big advantage 
%over other security mechanisms
is that they are expressed solely in terms of a program's underlying
object graph structures, and the evolution of those graphs as programs run
\cite{aliasaswec98}. 
%
Security then reduces to reachability, in both space
(over the object graph) and time (over the program's execution).
Unfortunately, as in any
object-\textit{oriented} program, a program's execution modifies its
object graph.  In an object-\textit{capability}
program,
modifications are  limited by the
capabilities accessible to  each object at each point in a program's
execution \cite{permissionAuthority}.
%
In object capability terms, an object has \textit{permission} to
invoke methods on another object if it holds a reference (a
capability) to that object.  Because object-capabilities are
unforgeable, ``only connectivity begets connectivity'' \cite{ELang},
and so the only way one object $a$ can get permission to another
object $b$ is from a third object $c$ which has permission to
$b$.  Similarly, one object $a$ only has \textit{authority} to change
another object $b$ if $a$ has permission for $b$, or if $a$ has
permission for $c$ where $c$ has authority to change $b$
\cite{wyverncapabilities,permissionAuthority}.

Permission and authority characterise a system's security requirements.
For example, a core requirement of a cryptocurrency system is that
a program only has authority to transfer money from a digital wallet
when that program has permission to access 
the  wallet holding the money --- that is, when the program can
access the wallet object 
via the program's underlying object graph.
%
Indeed such a guarantee is claimed
(but not specified nor proven)
for the Solidity currency system \cite{SolidityCoin}.  Unfortunately,
programming errors let untrusted external code change some Solidity
objects' implementations in ways its designers had not anticipated,
which lead directly to the ``MultiSig''
wallet bugs in July and October 2017
\cite{SolidityMultiSigJuly,SolidityMultiSigNovember}, each costing
above 100 million dollars.
%
If authority over wallets was not leaked,
then untrusted objects would not have been able to change the wallets
necessary to exploit the bug.

While object capabilities make it \textit{possible} to write secure
programs, they cannot \textit{ensure} programs are
secure. 
%Every program has its own security criteria: the challenge for
%programmers is how to demonstrate that their program designs meet
%those criteria. 
This is what it means for a program to be
\textit{robust}: that a program will continue to function correctly
in spite of any untrusted code with which it interacts.
%
Formal verification offers the possibility of mathematically proving
programs robustly meet their specifications, however verification of
object-capability programs has only been studied very recently (e.g.\
our work and :quuuuuuuu 

% The difficulty here is that while
% most program verification establishes \textit{sufficient} conditions
% (ensuring objects do the right thing for trusted code),
% verification of program robustness must also consider
% \textit{necessary} conditions (ensuring objects do not do the wrong
% things even when interacting with untrusted code).

% This is because verifying the
% security of object-capability programs differs from verifying more
% traditional object-oriented programs in several important ways.
% Functional verification describes the services offered by objects to
% clients, while robustness verification describes how objects can to
% protect themselves against attacks by their clients.
% Functional verification addresses the necessary conditions for an
% operation to succeed, while robustness verification addresses the
% sufficient conditions for an object not to be compromised. That is,
% functional verification demonstrates that objects will do the right
% thing. while robustness verification ensures that objects cannot do
% the wrong thing.

We have developed techniques so programmers can write
object-capability polices that explicitly specify a program's
desired behaviour
\cite{capeFTfJP,iFM2014,FTfJP14,murray10-infoflow,murray10dphil,lefthand,chainmail}.
Programmers can define policies such as ``permission to access some
data does not grant permission or authority over the source of that
data'', ``the authority to change a wallet's owner is restricted to
its existing owner'', or ``If I trust my bank, I will trust the
digital wallets it issues'', with each policy capturing a particular
security requirement, and so preventing a particular class of bugs. We
have developed a range of capability examples including a currency
system, grant matcher, escrow agent, and web document model, and have
hand-developed individual proofs that the escrow agent and web
document programs satisfy their policies
\cite{swapsies,attenuation,permissionAuthority}.




Two recent efforts to tackle this problem are Swasey et al.\
\cite{ddd} and Devrise et al.\ \cite{dd}.  Swasey et al.\ show how
wrapping capabilities which may be exposed to untrusted objects can
ensure the robustness of some object capability patterns, while
Devrise et al.\ show how step-indexing, Kripke worlds, and representing
objects as state machines with public and private transitions can be
used to construct reason about object capabilities in general.
%
Neither effort addresses specification languages for security and
robustness, provides Hoare logics to reason about object-capability
programs, model protocols that dynamically ascribe trust
\cite{swapsies,lefthand} or quantify the damage an untrustworthy
object can do.

%\end{spacing}

%----------------------------------------------------------------------
\pagebreak
%----------------------------------------------------------------------

%----------------------------------------------------------------------
%\vspace*{1cm}
\noindent {\bf 2B.   OVERALL AIM OF THE RESEARCH}\\
%----------------------------------------------------------------------
%{\tiny \\ {\scriptsize Use this section to state the general goals
%and specific objectives of the research proposal. Outline the
%potential for significant scholarly impact of your proposal
%(incorporating novelty, originality, insight and ambition). {\bf
%Please use a MAXIMUM of 6 pages for sections 2A-2D combined if you
%have tickerd one or more Vision M\=atauranga themes in section 3, or
%a maximum of 5 pages for 2A-2C combined if you have ticked N/A in
%section 3.} These instructions should be removed; please do not
%change the margins.} \par} 
%----------------------------------------------------------------------
% ENTER the Overall Aim of the proposal.
%----------------------------------------------------------------------
%
The general goal of this project is to verify that object-capability
programs are robust and secure, by ensuring they satisfy their
capability policy specifications. To meet this goal, we will develop
formal frameworks to describe programs and their specifications, and
program logics to verify that programs do meet those specifications.

Our project has four objectives. First, we will develop a formal model
of a core object-capability language in a program verification proof
tool. We will then use the tool to prove that the language supports
the key properties of the object-capability model.

Second, we will formalise and verify a specification language so that
programmers can make precise statements about the intended behaviour
of robust programs \cite{chainmail}.  Building on a base assertion
language, we are developing a specification language that incorporates
special predicates which talk about permission and authority, i.e.\
the access and modification of objects
\cite{iFM2014,swapsies,permissionAuthority}, the trust programs must
place on external objects they interact with, and modal operators to
address the program's past or future states \cite{HolisticWG2.3}.  

We
have hand proofs of soundness for most of our specification language
--- unfortunately, we do not yet have definitions that capture the
semantics of \textit{trust} between objects.  We need to break a
circular argument that comes from the fact that trust can be
conditional: trust in one object (a digital wallet) can depend on
trust in another object (the bank that issued the wallet).  This
dependency creates a cycle in the mathematics underlying the proof,
and this has been resistant to the approaches we have attempted so far.

Third, we will formalise and verify a novel program logic, the Logic
of Risk and Trust, that can be used to demonstrate that an
object-capability program has the behaviour expected by that program's
specifications. 
%
%
This kind of verification requires guarantees about capability
policies that cannot easily be expressed in standard Hoare Logics
\cite{Hoare69}. Capability policies must talk about {\em necessary}
conditions for an effect to happen, while Hoare logics are
traditionally about {\em sufficient} conditions.  Traditional program
logics are based on Hoare triples (describing the state before some
code is executed, the code itself, and the state afterwards).
We have
an initial design for an extended Hoare logic based on quadruples, and
we have completed some manual examples showing the potential of this
logic to support proofs of robustness and security. The key to
this logic is the fourth component of the quadruple which reifies an
invariant that must hold at all times during the execution of the
code, and can encode the necessary conditions needed for our
specifications.


Finally, we will validate our specification language and program logic 
by verifying a corpus of programs. Working from object-capability
exemplars,  benchmark programs, and building programs to replicate
significant bugs, 
we will build a corpus of programs whose behaviour we understand. 
We will then write capability policy specifications to capture what it means
for each program to be robust, and then verify that each program meets
its specifications.

Underpinning each of these objectives is a commitment to working
within a modern program verification and proof tool such as Coq, Dafny
or Isabelle \cite{Z3,Dafny10,boogie12,Viper,coqbook}. (We will select
a tool as part of the first objective, guided by the experience of the
postdoc who will work on the project). Working with a verification
tool will not only assist in completing the necessary proofs (computer
science publication venues increasingly require artifacts such as
proofs or programs to be lodged along with final copies of papers)
but could also lead to practical tools which could be adapted for use
outside the project. 



\sparagraph{Impact}

At the conclusion of this project, our ambition is that software
engineers will be able to ensure that programs are robust and
secure, by verifying that their programs satisfy their capability
policies.  We will have developed novel techniques and tools for
program verification, based on original formal models for
specifications and program logics, relying on our insights into
object-capability programs
\cite{permissionAuthority,lefthand,arnd18} and 
programmers' security requirements \cite{charlesFSE16,charlesSOUPS16}.
This project will
draw on our experience in programming language
design including ownership types
\cite{multiple,existOwn,ClaPotNobOOPSLA98} 
capabilities for sharing~\cite{capsForSharing}, first
class relations~\cite{RelAspects}, 
empirical studies of
programming~\cite{howInheritance,NelsonPN12,WatermanICSE15,HodaICSE17}, and the
Grace language~\cite{grace,graceDLS}.  Finally, existing large-scale
software engineering efforts such as the Rust
\cite{RustPL2,RustBelt18} and Scala Programming Languages
\cite{ScalaCapabilities,ScalaBorrowing2017}, the Java Modelling Language
\cite{Leavens-etal07} and HabaneroJava \cite{WestbrookZBS12}, and
Microsoft's VCC \cite{hypervisor}, Spec$\sharp$ \cite{specsharpcacm11}, and
C$\sharp$ \cite{GordonPPBD12,CsharpMem2017} have built on our previous
work: this project promises similar impact.




%----------------------------------------------------------------------
\pagebreak
%----------------------------------------------------------------------
\noindent {\bf 2C.   PROPOSED RESEARCH}\\
%----------------------------------------------------------------------
% {\tiny \\ {\scriptsize  This section should cover where appropriate
% the hypotheses being tested, the methodology to be used, sampling
% design, and methods of data analysis. Please ensure that your
% description covers the entire research programme, including
% contributions by collaborators and any postgraduate students.  If
% you have identified one or more Vision M\=atauranga themes in
% Section 3, you may want to include discussion of this within
% Sections 2A-2C, for example, on consultation and linkages,
% relevance, conceptual framework and/or proposal design, and
% outcomes, in addition to statements in Section 2D. If the proposed
% research requires ethics approval, you may wish to include
% discussion of all the relevant ethical issues, and possible
% implications of your research. {\bf Please use a MAXIMUM of 6 pages
% for sections 2A-2D combined if you have tickerd one or more Vision
% M\=atauranga themes in section 3, or a maximum of 5 pages for 2A-2C
% combined if you have ticked N/A in section 3.} These instructions
% should be removed; please do not change the margins.} 
%\par}
%----------------------------------------------------------------------
% ENTER the Proposed Research.
%----------------------------------------------------------------------
%
\sparagraph{Objective 1: Formal Foundations}

\newcommand{\Methodology}{\vspace{.01in}{ \noindent {\it Methodology}:\, }}

\newcommand{\FB}{$\mathcal{F\!B}$}
\newcommand{\CA}{$\mathcal{C\!A}$}
\newcommand{\DATA}{$\mathcal{D}$}
\newcommand{\MODEL}{$\mathcal{M}$}

\newcommand{\PAST}{$\lhd\,$}
\newcommand{\FUTURE}{$\rhd$}
\newcommand{\NOT}{$\neg$}
\renewcommand{\AND}{$\wedge\,$}
\renewcommand{\OR}{$\vee\,$}
\newcommand{\EQUIV}{$\Longleftrightarrow\,$}


\newcommand{\Access}{\textrm{Access}}
\newcommand{\Call}{\textrm{Call}}
\renewcommand{\obeys}{\textbf{obeys}}


\noindent We will begin by formalising and proving the semantics of a model
object-capability programming language.  We have already identified
the features we require in a language, and the object-capability
properties that must be maintained by program executions, such as
absence of ambient authority, and only connectivity begetting
connectivity \cite{swapsies,HolisticWG2.3}.  The challenges here are
first, to encode the language model in a suitable formal tool; second,
to prove the language maintains those properties via the tool; and
third, to do so in a way that will provide a solid foundation for the
project as a whole.

We want our work to be applicable to both statically- and
dynamically- typed languages, because of the wide variety of languages
used to build contemporary applications \cite{thornPOPL,dart15}.  To
allow us to keep the model tractable, and to concentrate on the core
problem of object-capability security, we need a language with simple,
regular semantics but which avoids the unnecessarily intricate
features found in web languages in practice
\cite{crockford2008,essence,reasonJS}.  We plan to work in the
Grace~\cite{grace,graceBrands} programming language that supports both
static and dynamic types around a simple object-capability core.  

\Methodology We will build the formal model by adapting and extending
existing formalisations of object-capability languages.
\cite{MackayFJCoq,reasonJS,graceClasses}.
%
We will encode the model in a 
specification language supported by an existing program verifier or
theorem prover \cite{Z3,Dafny10,boogie12,Viper,coqbook}, and then
verify proofs that the language supports the execution properties we
expect.

This work will primarily be carried out by the postdoc, supervised by
Noble, drawing on the expertise of Drossopoulou and Murray with
verification and proof tools.  We expect this objective will be
straightfoward as it relies on well understood techniques, albeit
applied in an original context.  This objective is a necessary
precursor to the rest of the project, and will provide a good
introduction to the project for the postdoc.




















\sparagraph{Objective 2: Capability Policy Specifications}

\noindent In the second objective we will formalise and prove
soundness for a specification language to express object-capability
policies.  Consider a social networking system \FB\ that
supplies data \DATA\ to an analytics company \CA\ --- e.g.\ by
executing  ``\textsf{\CA.analyse(\DATA)}''.
From an object-capability perspective, the key outcome of this
statement is to give \CA\ permission to access the data.  A social
network needs to protect its data, and so should enforce a
policy that a third party (such as \CA) can only access data
explicitly handed to it by \FB.  
We have developed a design for a specification language, called Chainmail, 
which can express this policy.
% Chainmail's capability and modal operators
We write \Access($x$,$y$)
to mean that some object $x$ has permission to access to another
object $y$, and $x$.\Call($y$.\textsf{m},$z$) to mean object $x$
invokes method \textsf{m} on object $y$ passing $z$ as an argument:


% \noindent
% \framebox[\textwidth][l]{
% \Access(\CA,\DATA) $\rightarrow$ \PAST\FB\textrm{.Call}\textsf{(\CA.analyse(\DATA)}
% }

\vspace*{1mm}
\begin{lstlisting}
%\Access(\CA,\DATA) $\rightarrow$ \PAST\ \FB.\Call\textsf{(\CA.analyse(\DATA))}%
\end{lstlisting}
\vspace*{-7mm}

This policy states that if (at some point in the program's execution)
the \CA\ object has access to the data \DATA, then at some preceding point
in the program (\PAST is a modal operator referring to previous
execution states) the \FB\ object \textit{must} have passed that
data explicitly to \CA.   
%
% Unfortunately, using only this policy, once a
% third party such as \CA\ has been granted access to data, they retain
% access to it indefinitely.
%
We can extend the
policy so that \CA\ can be instructed to \textsf{forget} the data:
% 
% after which it should no longer have permission to \DATA has access
% --- unless it is subsequent granted it again:
%
\vspace*{1mm}
\begin{lstlisting}
%
\Access(\CA,\DATA) $\rightarrow$ \PAST\ (\PAST
\FB.\Call\textsf{(\CA.analyse(\DATA))} \AND 
\NOT \FB.\Call\textsf{(\CA.forget(\DATA))})
%
\end{lstlisting}
\vspace*{-7mm}



% The most difficult problem in dealing with programs in an open world
% is that the objects in our programs have to interact with untrusted
% objects from other programs.  If our programs are to be
% \textit{robust} then the trusted parts of the system must not be able
% to be compromised by untrusted objects coming in from outside
% \cite{mitre-unforgivable}.

The reason why secure programs must be robust is that they have to
interact with untrusted objects.
% from the open world. 
Consider the situation in the data-analytics model when
\CA\ cannot be trusted by \FB. 
%
% In an object-capability system, when \FB\ directly hands out data to
% \CA, it gives \CA\ permission to access that data, and authority to
% change it \cite{permissionAuthority}.
%
% In an open world, however, such trust may be unfounded. 
% 
%
When \FB\ asks \CA\ to forget the data, \FB\ \textit{implicitly
  trusts} that \CA\ will do what it promises.  To reason about the
behaviour of these kind of programs in open world, we need to consider
both the case where \FB\ is trustworthy, and crucially, \textit{the
  case where it is not.}

We have designed specification constructs to handle these cases, and
inference rules to use them in reasoning. We write ``\CA\ \obeys\
$S$'' to mean that \CA\ is trustworthy: more particularly, to mean
that \CA\ obeys a specification $S$ \cite{swapsies}.  Here ``\obeys''
is an opaque predicate that records our assumptions of trust. We
cannot directly ask \CA\ whether it obeys the specification $S$
because of the Cretan paradox: in an open world, an untrustworthy \CA\
can answer true as easily as false.
Revisiting the example, 
incorporating trust means that we cannot conclude that a
\textsf{forget} request will in fact have \CA\ lose access to the
data: rather we can conclude this only in contexts where we are
willing to assuming that \CA\ behaves as expected:

% \begin{lstlisting}
% %\CA%.forget(%\DATA%)
% assert %\CA\ \obeys\ $S$ $\rightarrow$ \NOT \Access(\CA,\DATA)%
% \end{lstlisting}

\vspace*{1mm}
\begin{lstlisting}
%
\CA\ \obeys\ $S$ \AND
\Access(\CA,\DATA) $\rightarrow$ \PAST\ (\PAST
\FB.\Call\textsf{(\CA.analyse(\DATA))} \AND 
\NOT \FB.\Call\textsf{(\CA.forget(\DATA))})
%
\end{lstlisting}
\vspace*{-7mm}

Explicitly representing trust via \obeys\ means that Chainmail
specifications can quantify the \textit{risks} of dealing with
untrusted objects, answering the question ``\textit{how much damage
  can an untrustworthy object do?}''  Object-capability properties
such as  ``only connectivity begets connectivity'' enable us to
calculate these bounds, by ensuring that an untrustworthy object
cannot damage an object that it cannot access.
%
In our example, even if \CA\ does not behave the way \FB\ hopes, the
worst it can do is retain the data it was given. \CA\ can never take
control of the network as long as it is never given permission to access \FB.

% neither \CA\ nor the data are granted permission to
% \FB, permission that would grant authority to control the entire
% social network. 

% In an open world, a robust system must function correctly even in the
% presence of external code of uncertainly provenance.  The question we
% need to answer is: \textit{how much damage can an untrustworthy object
%   do?} --- that is we need to bound the \textbf{risk} to a program
% that must deal with an untrusted object. Here, again, the
% object-capability model is critical: a potentially untrustworthy object
% cannot damage an object that it cannot access. 

% In our example, by design of the \FB\ system we can ensure that
% neither \CA\ nor the data are granted permission to control \FB\ (i.e.\
% access to the \FB\ object).  \CA\ has access to \DATA\ but is
% requested to \textsf{forget} it. If \CA\ obeys its specification $S$,
% it will lose access to the data; but if \CA\ does not obey its
% specification, we take the worst case: \CA\ can still access any object
% it could before the \textsf{forget} request --- but it cannot gain
% ambient permission to access other objects in the system. 
% So while an untrustworthy \CA\ can retain access to the \DATA\ it was
% passed, it cannot get access to the whole of \FB.










\Methodology We have a definition of the Chainmail language, including
the novel access assertions and the modal operators
\cite{chainmail,HolisticWG2.3}, and hand proofs of soundness for most
of the language.
The critical remaining problem is to define the
semantics of \textit{trust} precisely.  Our current working definition
contains a circular argument from the fact that trust can be
conditional: trust in one object (e.g.\ some data) can depend on trust in
another object (the network that exported the data).  
The formal semantics of an object obeying a specification can
depend on \textit{another} object obeying a different 
specification, thus the circularity.
%
We plan to address this problem by adapting step-indexing techniques
\cite{stepindex,dd} to our model, but without exposing the complexity
that induces to users of the proof system. 
%
%
This work will be carried out in two stages.  Noble and Drossopoulou
will develop revised semantic definitions for Chainmail and thus
resolve the circularity, and then the postdoc will work on
incorporating the definitions into the formal verification tool used in
Obj.~1.





















% In an open world, a robust system must function correctly even in the
% presence of external code of uncertainly provenance.  The question we
% need to answer is: \textit{how much damage can an untrustworthy object
%   do?} --- that is we need to bound the \textbf{risk} to a program
% that must deal with an untrusted object. Here, again, the
% object-capability model is critical: a potentially untrustworthy object
% cannot damage an object that it cannot access. 

% In our example, by design of the \FB\ system we can ensure that
% neither \CA\ nor the data are granted permission to control \FB\ (i.e.\
% access to the \FB\ object).  \CA\ has access to \DATA\ but is
% requested to \textsf{forget} it. If \CA\ obeys its specification $S$,
% it will lose access to the data; but if \CA\ does not obey its
% specification, we take the worst case: \CA\ can still access any object
% it could before the \textsf{forget} request --- but it cannot gain
% ambient permission to access other objects in the system. 
% So while an untrustworthy \CA\ can retain access to the \DATA\ it was
% passed, it cannot get access to the whole of \FB.



% Rather, the rules in our program logic
% for method calls enforce a precondition that the receiver of a call
% must obey our specification of that call --- the rule below requires 
% a method receiver \prg{x} \obeys\ $S$ as part of the precondition.

% \newcommand{\HoareCSep}% the separator for the conclusion
% {\Join}
% \newcommand{\Hoare}[4]
% {{\ensuremath{\vdash  \,{#1}\,  \{\, {#2}\, \}\  {#3}\ \HoareCSep\
%       {#4} }}}

% \[
% \begin{array}{l}
%    { \M(S) \,= \,  \kw{spec}\ S\  \lb\  \overline{Policy}, \A \,\lb \, \prg{this.m(par)}\, \rb\, \B, \overline{Policy'}\  \rb}
%    \\  \hline {
%     \Hoare{\prg{x}~\obeys~S\wedge  \A[\prg{x}/\prg{this},\prg{y}/\prg{par}]} {\prg{v} \, \kw{:=}\, \prg{x.m(y)}} {\B[\prg{x}/\prg{this},\prg{y}/\prg{par},\prg{v}/\prg{res}]}   {{\true}} % {\B'''}
%   }
% \end{array}
% \]



% \begin{lstlisting}
% assert %\NOT \Access(\CA,\FB) \AND\ \NOT \Access(\DATA, \FB)%
% assert %\Access(\CA, \DATA)%
% %\CA%.forget(%\DATA%)
% assert %\CA\ \obeys\ $S$ $\rightarrow$ \EQUIV\ \Access(\CA,\DATA)%
% assert %\NOT \Access(\CA,\FB) \AND\ \NOT \Access(\DATA, \FB)%
% \end{lstlisting}


% \Methodology Based on our collection of object-capability idioms and
% case studies, we will design language features, and their supporting







\sparagraph{Objective 3: Logic of Risk and Trust}

\noindent Our third objective is to formalise and prove a program logic to
verify that object capability programs (from Obj.~1) meet their
specifications (from Obj.~2).
The Logic of Risk and Trust will allow programmers to guarantee their
programs are robust against the risk posed by untrusted objects, 
and so are worthy of trust themselves.
%
For example, consider the simple code fragment below from
within \FB:
%
% \PAST\ \FB.\Call\textsf{(\CA.analyse(\DATA))
%
\vspace*{1mm}
\begin{lstlisting}
assume %\PAST\ \NOT\ \FB.\Call%(%\CA%.analyse(%\DATA%))
//
assert %\NOT \Access(\CA,\DATA)%
do_something( %\CA%, %\DATA% )
assert %\NOT \Access(\CA,\DATA)%
// 
assert %\PAST \NOT \Access(\CA,\DATA)%
\end{lstlisting}
\vspace*{-7mm}
%
Given we know that \CA\ has never accessed \DATA\ at the beginning of
the computation, and that the execution of the
\lstinline+do_something+ method begins and ends in a state where \CA\
cannot access \DATA, a standard Hoare logic will let programmers prove
that \CA\ has never accessed \DATA\ at the end of the computation.
While this reasoning is sound for traditional functional code
invariants, it is insufficient for reasoning about permission and
authority in object-capability programs.
%
To see why, consider the alternative code below (lines 13--15
are an alternative to lines 6--8, or can be thought of as an
implementation of the 
\lstinline+do_something+ method). 


\vspace*{1mm}
\begin{lstlisting}
assume %\PAST\ \NOT\ \FB.\Call%(%\CA%.analyse(%\DATA%))
//
%\CA%.analyse(%\DATA%)
assert %\Access(\CA,\DATA)%  
%\CA%.forget(%\DATA%)
//
assert %\PAST \Access(\CA,\DATA)% //bad
assert %\CA\ \obeys\ $S$ \EQUIV \NOT \Access(\CA,\DATA)%  //worse
\end{lstlisting}
\vspace*{-7mm}

\noindent Here, \CA\ most definitely has permission to \DATA\ in the
past, and may still, if it turns out that \CA\ is not trustworthy.  The
central problem here is that standard Hoare logics and associated
proof techniques such as class invariants \cite{Parkinson07} make
guarantees that hold only at particular program points
\cite{DrossoFrancaMuellerSummers08}.  This is intentional: a class
invariant for a doubly-linked list must be broken temporarily to
insert a new node; a loop invariant is typically broken and restored
each time around the loop. Standard program logics cannot describe the
crucial point that \DATA\ must never be exposed to \CA\ at any step of
computation.
%
This is similar to the well-known ``ABA'' problem \cite{aba} in
concurrent systems, where one thread changes a variable and then
restores its original value, except here the problem arises even in
sequential code.


\Methodology Traditional program logics are based on Hoare triples ``$P$
\lstinline+{C}+ $Q$'' (the precondition $P$ characterising the state
before some code is executed, the code \lstinline+C+ itself, and the
postcondition $Q$ characterising the state afterwards) \cite{Hoare69}.
We will address this by developing an extended Hoare logic based on
quadruples: ``$P$ \lstinline+{C}+ $Q \bowtie R$'' where a fourth
component $R$ is a ``rely'' condition that must hold at all program
points \textit{during} the execution of \lstinline+C+.  These 
are derived from rely-guarantee logics for reasoning about concurrency
\cite{jonesTOPLAS83,MPC-Staden15,concur2007}.
% \cite{AOP-RG-FOAL-08}
In concurrent reasoning, one thread's rely conditions are established
by complementary guarantees  from other threads. Our proposal
does not need a guarantee,  because our rely conditions
constrain the behaviour of our own code to ensure robustness.

The following Hoare rule shows how method calls and a key property of
object-capability systems (that ``only connectivity begets
connectivity'' \cite{ELang}) can be represented using this technique.
This rule promises in the postcondition $\Q$ that the result~\prg{v} of the
method call~\prg{x.m(y)}  
cannot expose access to any object \prg{z} that wasn't
initially accessible to the method call's receiver~\prg{x} or argument~\prg{y}.
The rely condition $\R$
also promises that
accessibility does
not change 
{\em during} execution of the method,
unless the participants (here \prg{z}  and \prg{u})
were accessible to the receiver and/or the argument {\em before}
the call:



\newcommand{\HoareCSep}{\Join}% the separator for the conclusion
\newcommand{\Hoare}[4]
{{\ensuremath{\vdash  \,{#1}\,  \{\, {#2}\, \}\  {#3}\ \HoareCSep\
      {#4} }}}

\[
\begin{array}{l}

         \Q \equiv \forall \prg{z}: \Access({\prg{v},\prg{z}}) \rightarrow  
    \, \lhd\, (\, \Access(\prg{x},\prg{z})\, \vee \, \Access(\prg{y},\prg{z})\, )\\
   \R \equiv   \forall \prg{z},\prg{u}: ( \ \Access({\prg{u},\prg{z}}) \rightarrow \\
       $ ~ $ \hspace{1.3in} \lhd\ ( \Access(\prg{u},\prg{z}) \ \ \ \vee  \\
                 $ ~ $ \hspace{1.7in}(\  (\Access({\prg{x},\prg{z}})\vee \Access({\prg{y},\prg{z}}) )\ \wedge \\
                 $ ~ $ \hspace{1.8in}  (\Access({\prg{x},\prg{u}})\vee \Access({\prg{y},\prg{u}}) ) \ ) \ ) \ \  )  
    \\  \hline {
    \Hoare{\true} {\prg{v} \, \kw{:=}\, \prg{x.m(y)}} {\Q}
           { \R  } 
    }
\end{array}
\]



This work will be carried out by Noble and Murray, building on the
formal infrastructure established by the postdoc.  (The postdoc will
likely have finished on the project before much progress is made on
this objective).  Although this objective will be complex, based on
our preparatory work on paper, we expect it to be tractable given 
we have the formally verified models from Obj.s~1~\&~2.

% In rely-guarantee reasoning, one thread's rely invariants are
% established by complementary guarantee invariants.
% In our proposal, rely invariants constrain the value of OUR OWN code,
% The key insight of our proposal, however, is that our logic only needs
% rely invariants: in an open world, robust code CANNOT depend on other
% components maintaining guarantees to ensure our code meets its
% specifications. 






\sparagraph{Objective 4: Validation}

\noindent In the final objective, we will validate that our program logic
(Obj.~3) can verify that capability specifications (Obj.~2)
are obeyed by object-capability programs (Obj.~1).
%
%At the beginning of the project, 
\sd{We will} collect code examples from the literature \cite{MillerPhD,murray10dphil,murray10-infoflow,membranesJavascript,ELang,refinementForSecure,enforcing},
as well as security mechanisms
\cite{FeatherFirefox,Java2Security,adsafe,KeyKOS}, of around 10-50 lines
of Grace program code,
write 
capability specifications for those programs, and then verify them
using our program logic.
. %with the aim   to end up with a series of little examples, demonstrating typical requirements.
%We will describe these  in words, and  in code.
% Our findings will affect {\bf Obj.1} and {\bf Obj.3}.
Towards the end of the project, \sd{we} hope to consider a larger case
study, e.g.\ the core of a browser or web application server
($\approx$~250~lines, \cite{FeatherFirefox}).
%
% Throughout the project, we will be evaluating our work through
% these case studies,  and discussing our findings with industry.
%
%

%Moreover, we will  follow the hybrid
%approach \cite{hybrid} whereby  the tool will statically check as much as it can, and will check the rest dynamically.

%\textit{nice stuff in section 2 refactor into here --- make sure this
%  sounds tentative!}




\Methodology
This objective will be carried out primarily by graduate students and
RAs, supervised by Noble.  
The main task will be iteratively attempting to verify programs against
specifications, and then adjusting the programs, the specifications,
or requesting changes to the formal tools whenever an attempt fails.
This validation effort will begin in parallel with the
other objectives, but will naturally gain momentum towards the end of the
project.


%FROM 2013 application
% For deny conditions involving causal events
% and state changes, we plan to generate additional data structures in
% Dafny to model the execution of the Grace program --- e.g.\ a Dafny
% sequence to model the program event trace --- and then verify
% assertions in terms of those additional structures. For deny conditions
% that prevent capability leakage, we will extend recent work on
% ownership types and ownership inference
% \cite{kacheck,aliasesNecessary,dde11,milanova2011,milanova2012}. 


\sparagraph{Dissemination of Results}

Our previous Marsden funded work in this area has been well
cited. This project will build on that record to transfer knowledge to
the software engineering community via the traditional avenue
of papers in prestigious conferences and
journals (OOPSLA, ECOOP, ICSE, ESOP, IEEE TSE, ACM TOPLAS). We will also
interact with the research community through invitation-only workshops
such as those associated with the IFIP Working Groups WG2.16
(Programming Language Design, Noble is a founder member) and WG2.3
(Programming Methodology, Noble and Drossopoulou are both invited
observers).

The project will produce formal theories that mechanise the capability
policy specifications, program logics, the logics’ and specifications
proofs of soundness, and the proofs for the case studies.  These will
all be made available open-source on the Archive of Formal Proofs
(http://www.isa-afp.org) for others to use. 


% The project will also
% produce source code for case studies and modifications to
% implementations of the Grace programming language: all code will be
% placed under open source licences and made available on GitHub.  Where
% publications are supported by source code or formal models, that code
% and models will be formally submitted for artefact evaluation --- the
% majority of the venues where we publish, both journals and
% conferences, now maintain artefact archives.




%----------------------------------------------------------------------
%\pagebreak
%%----------------------------------------------------------------------
%%----------------------------------------------------------------------
%%\noindent {\bf 2D.   VISION M\=ATAURANGA}\\
%%----------------------------------------------------------------------
% %{\tiny \\ {\scriptsize If you identify one or more Vision M\=atauranga themes in Section 3, please provide a brief summary of the consultation process so far and plans for ongoing consultation. M\=aori applicants undertaking M\=aori research should demonstrate their linkages and what processes they have used in developing and designing their proposal. If unsure or in doubt about the relevance of the proposal for M\=aori, the researchers should consult their institutional advisor and should spell out their rationale in this section. Please refer to the relevant sections in the {\it 2087 Full Proposal Guidelines for Applicants}. {\bf Please use a MAXIMUM of 6 pages for sections 2A-2D combined if you have tickerd one or more Vision M\=atauranga themes in section 3.}  Instructions should be removed.}
% %\par}
% %%----------------------------------------------------------------------
% %% ENTER the Proposed Research.
% %%----------------------------------------------------------------------
% %xxxxxxxx xxxx xxxxx xxx xxxxxx xxx xxxxxxxx xxxxx xxxxxx xxxxxx
% %xxxxx xxx xxxxx xxxxxx xxxxxxxxx xxxxx xxxxx xxxx xxxxxxxx xxxxx
% %xxxxxxx

%----------------------------------------------------------------------
\pagebreak
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\noindent {\bf 2E.   REFERENCES}\\
%----------------------------------------------------------------------
% {\tiny \\ {\footnotesize Please list references for Sections
% 2A-2D. Use a {\bf maximum} of 3 pages. Full titles should be
% included. Please bold any applicants' names if they appear in the
% reference list. Instructions should be removed.} 
%\par
%\def\refname{}
%----------------------------------------------------------------------
%\begin{thebibliography}{11}
%----------------------------------------------------------------------
% ENTER the References.
%----------------------------------------------------------------------
\parindent 0cm
\vspace*{-7mm}
\begin{spacing}{0.85}
\printbibliography[heading=none]
\end{spacing}

% \setlength{\itemsep}{0pt}
%\begin{spacing}{0.95}
%\bibliographystyle{plainnat}
%\bibliographystyle{abbrvnat}
%\bibliography{Case}
%\end{spacing}

%----------------------------------------------------------------------
%\end{thebibliography}
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\end{document}
%---------------------------------------------------------------------
