\paragraph{Behavioural Specification Languages} 

Hatcliff et al.\ \cite{behavSurvey2012} provide an excellent survey of
contemporary specification approaches.  With a lineage back to Hoare
logic \cite{Hoare69}, Meyer's Design by Contract \cite{Mey88} was the
first popular attempt to bring verification techniques to
object-oriented programs as a ``whole cloth'' language design in
Eiffel.  Several more recent specification languages are now making
their way into practical and educational use, including JML
\cite{Leavens-etal07}, Spec$\sharp$ \cite{BarLeiSch05}, Dafny
\cite{dafny} and Whiley \cite{whiley15}. Our approach builds upon
these fundamentals, particularly Leino \& Shulte's
%\kjx{and Naumann's} 
formulation of
two-state invariants \cite{usingHistory}, and Summers and
Drossopoulou's Considerate Reasoning \cite{Considerate}.
%
In general, these approaches assume a closed system, where modules
can be trusted to co{\"o}perate. In this paper we aim to illustrate
the kinds of techniques required in an open system where modules'
invariants must be protected irrespective of the behaviour of the rest
of the system.

\james{stuff moved from intro that shojld go somewhere}
\susan{I would stop after the first sentence - the other points
perhaps in related work} \james{yes. moved\ldots}
\kjx{this setenvce is still in intro: Necessary conditions are guarantees upheld throughout program execution.}
Other systems which give such ``permanent'' guarantees are  type systems, 
which ensure that well-formed programs  always produce well-formed runtime
configurations, or information flow control systems \cite{infoflow}, which ensure that values 
classified as high  will not be passed into contexts classified as low. 
Such  guarantees %made by types or information flow control
 are  practical to check, but   too coarse grained
for the purpose of fine-grained,  module-specific specifications. 


Because \Chainmail\ specifications can cross-cut the code they are
specifying, \Chainmail\  is also related to 
aspect-oriented specification
languages such as AspectJML \cite{AspectJML} and AspectLTL
\cite{AspectLTL}.

AspectJML is an aspect-oriented extension to JML,
in much the same way that AspectJ is an aspect-oriented extension to
Java \cite{AspectJ}.  AspectJML offers AspectJ-style pointcuts 
that allow the definition of crosscutting specifications, such as 
shared pre- or post-conditions for a range of method calls. These
crosscutting specifications can be checked dynamically along with
traditional object-oriented JML assertions. In contrast, \Chainmail\
specifications naturally cross-cut implementation and specification
modules without any special notation, although, lacking wildcards,
\Chainmail\ is not as flexible as AspectJML. To our knowledge, the
semantics of AspectJML have yet to be defined formally, although
earlier work by Molderez and Janssens describes the formal core of a
similar language \cite{DbCAspectJ}.

AspectLTL \cite{AspectLTL} is a specification language based on Linear
Temporal Logic (LTL). AspectLTL adds cross-cutting aspects to more
traditional LTL module specifications: these aspects can further
constrain specifications in modules. In that sense, AspectLTL and
\Chainmail\ both use similar implicit join point models, rather than
importing AspectJ style explicit pointcuts as in AspectJML.  AspectLTL
has a formal definition, as does \Chainmail; unlike \Chainmail,
AspectLTL has support for automated reasoning with an efficient
synthesis algorithm

% \paragraph{Concurrent Reasoning} Deny-Guarantee \cite{DenyGuarantee}
% distinguishes between assertions guaranteed by a thread, and actions
% denied to all other threads. Deny properties correspond to our
% requirements that certain properties be preserved by all code linked
% to the current module. Compared with our work, deny-guarantee assumes
% co{\"o}peration: composition is legal only if  threads adhere  to
% their deny properties. In our work, a module has to be robust  and
% ensure that these properties cannot be affected by  other code. 


Finally, our work is also related to the causal obligations in Helm et
al.'s behavioural contracts \cite{helm90}. Causal obligations all
programmers to sprecify e.g.\ that whenever one object recieves a
message (such as a subject in the Observer pattern having its value
changed) that object must send particular messags off to other objects
(e.g.\ the subject must notify its observers). \Chainmail's control
flow opeator ``$\Calls{s}{x}{m}{y}$'' allows programmers to make similar
specifications, (e.g. $\Calls{s}{p}{\prg{SetValue}}{v} \rightarrow \Future{\Calls{Notify}{}{}{}}$ --- when a subject recieves a \prg{SetValue} method,
  it must ``forward'' those messages to the observer.

\paragraph{Defensive Consistency}

%cute but wrong.
%To misparaphrase Tolstoy, secure systems are all alike;
%every insecure system is insecure in its own way
%\cite{WikipediaAnnaKareninaPrinciple}.

In an open world, we cannot relie on the kindness of strangers: rather
we have to ensure our code is correct regardless of whether it
interacts with friends or foes.
Attackers 
\textit{``only have to be lucky once''} while secure systems 
\textit{``have to be lucky always''} \cite{IRAThatcher}.

Miller \cite{miller-esop2013,MillerPhD} defines the necessary approach
as \textbf{defensive consistency}: \textit{``An object is defensively
  consistent when it can defend its own invariants and provide correct
  service to its well behaved clients, despite arbitrary or malicious
  misbehaviour by its other clients.''}  Defensively consistent
modules are particularly hard to design, to write, to understand, and
to verify: but they have the great advantage that they make it much
easier to make guarantees about systems composed of multiple components
\cite{Murray10dphil}.

Murray made the first attempt to formalise defensive consistency and
correctness~\cite{Murray10dphil}.  Murray's model was rooted in
counterfactual causation~\cite{Lewis_73}: an object is defensively
consistent when the addition of untrustworthy clients cannot cause
well-behaved clients to be given incorrect service.  Murray formalised
defensive consistency very abstractly, over models of (concurrent)
object-capability systems in the process algebra CSP~\cite{Hoare:CSP},
without a specification language for describing effects, such as what
it means for an object to provide incorrect service.  Both Miller and
Murray's definitions are intensional, describing what it means for an
object to be defensively consistent.


%% languagebased security:
%%  - sabeklfield, myers, volpano et al
 
More recently Swasey et al.\ \cite{ddd} have designed OCPL, a logic
for object capability patterns, that supports specifications and
proofs for object-oriented systems in an open world.  The key idea
here is to draw on verification techniques for security and
information flow: separating internal implementations (``high values''
which must not be exposed to attacking code) from interface objects
(``low values'' which may be exposed).  OCPL supports defensive
consistency (Swasey et al.\ use the term ``robust safety'' from the
security community \cite{Bengtson}) via a proof system that ensures
low values can never leak high values to external attackers. This
means that high values \textit{can} be exposed, and the behaviour of
the system described by considering attacks only on low values.  OCPL
is a program logic, and Swasey use that logic to prove a number of
object-capability patterns, including sealer/unsealer pairs, the
caretaker, and a general membrane. 

Schaefer et al.\ have recently taken a similar approach to Swasey,
adding support for information-flow security in a setting using
refinement to ensure correctness (in this case confidentiality) by
construction \cite{schaeferCbC}. Although designed to support
confidentialty, it seems likely that the information-flow guarantees
could also be used to ensure robustness.  By enforcing encapsulation,
both these aproaches share similarity with techniques such as
ownership types \cite{ClaPotNobOOPSLA98,NobPotVitECOOP98}, which also
protect internal implementation objects from accesses that cross
encapsulation bondaries.  Banerjee and Naumann demonstrated that these
systems enforce representation independence (a property close to
``robust safety'') some time ago \cite{Banerjee:2005}.

\Chainmail\ differs from this work in a number of ways. This work is
concerned primarily about mechanisms that ensure encapsulation aka
confinemnt, while we abstract away from any mechanism via the
$\External{}$ predicate. While \Chainmail's $\Using{}{}$ is related to Banerjee
and Naumann's region sets, the assertion languages here are mostly
traditional (extensions of) Hoare logics --- Swasey et al.\ build on a
concurrent separation logic. None of these systems offer the kinds of
holistic assertions addressing control flow, change, or temporal
operations that are at the core of \Chainmail's approach.


Devrise et al.\ \cite{dd}. have deployed rather more complex
theoretical techniques to address similar problems.  Devrise et
al.\ show how step-indexing, Kripke worlds, and representing objects
as state machines with public and private transitions can be used to
reason about object-oriented programs in general.
Devrise have demonstrated solutions to a range of exemplar problems,
including the DOM wrapper (replicated in our
section~\ref{sect:example:DOM}) and a mashup application.
Although the formal techniques are much more sophisticated than we
apply here, and consequently can e.g.\ reason about recursion where we
cannot, there are some similarities, e.g.\ with the distinction
between public and private transitions being related to the
distinction between internal and external objects.
As with Swasey et al.\ this work does not provide an holistic
assertion language like \Chainmail.
In contrast, \Chainmail\ is
meant for describing and reasoning about real code, and we provide an
expressive, extensional framework for evaluating defensive consistency
in actual open systems.
%

%% Neither effort addresses specification languages for security and
%% robustness, provides Hoare logics to reason about object-capability
%% programs.

%% , model protocols that dynamically ascribe trust
%% \cite{swapsies,lefthand} or quantify the damage an untrustworthy
%% object can do.






% \kjx{History-Based Specification and Verification of Scalable
%  Concurrent and Distributed Systems --- ICFEM15}


% \paragraph{Specifying Design Patterns}

% Techniques for specifying Design Patterns go back at least to 
% Helm's contracts \cite{Helm92}.

% more importantly: work on formalisation of design patterns.
% (again look at JC grant, even if refs are 5 years old)
% let's be shameless here...


\paragraph{Object Capabilities and Sandboxes.}
{{\em Capabilities} as a means to support the development of concurrent and distributed system  were developed in the 60's
by Dennis and Van Horn \cite{Dennis66}, and were adapted to the
programming languages setting in the 70's \cite{JamesMorris}. 
{\em Object capabilities} were first introduced~\cite{MillerPhD} in the early 2000s},
 and many recent % work attempts to manage
studies manage
or verify  safety or correctness of object capability programs.
Google's Caja \cite{Caja} applies   sandboxes, proxies, and wrappers
 to limit components'
access to \textit{ambient} authority.
% --- that is, capabilities that
%can be obtained from the wider environment, rather than being granted
%to a component explicitly.
Sandboxing has been validated
formally: Maffeis et al.\ \cite{mmt-oakland10} develop a model of
JavaScript, demonstrate that it obeys two principles of
object capability systems
%  (``connectivity begets connectivity'' and
%``no authority amplification''), and then % uses these principles to
and show  how untrusted applications can be prevented from interfering with
the rest of the system. 
Recent programming languages and web systems
\cite{CapJavaHayesAPLAS17,CapNetSocc17Eide,DOCaT14} including Newspeak
\cite{newspeak17}, Dart \cite{dart15}, Grace \cite{grace,graceClasses}
and Wyvern \cite{wyverncapabilities} have adopted the object
capability model.


\paragraph{JavaScript analyses.}
More practically, 
Karim et al. apply static analysis on
Mozilla's JavaScript Jetpack extension framework \cite{adsafe}, including
 pointer analyses. % In a different direction,
Bhargavan et al.\ \cite{DefJS}
extend language-based sandboxing techniques to support defensive
components that can execute successfully  in otherwise untrusted
environments.   Politz et
al.\ \cite{ADsafety} use a JavaScript type checker to check
properties such as
% \textit{``widgets cannot obtain direct references
 % to DOM nodes''} and
 \textit{``multiple widgets on the same page
  cannot communicate.''}
% --- somewhat similar in spirit to our \textbf{Pol\_4}.
Lerner et al.\ extend this system to ensure browser
extensions observe \textit{``private mode''} browsing conventions,
such as that \textit{``no private browsing history retained''}
\cite{Lerner2013b}.  Dimoulas et al.\ \cite{DPCC14} generalise the
language and type checker based approach to enforce explicit policies,
% although the policies  are restricted to
that  describe  which components  may
access, or may influence the use of, particular capabilities.
Alternatively, Taly et al.\ \cite{secureJS}
model  JavaScript APIs in Datalog, and then
carry out a Datalog search for an ``attacker'' from the set of all
valid API calls. 
% This search is similar to the quantification over
% potential code snippets in our model.
% The problem posed by the Escrow example is that it establishes a two-way
% dependency between trusted and untrusted systems --- precisely the
% kind of dependencies these techniques prevent.

% %These approaches are all based on static analyses.
%  The WebSand
% \cite{flowcaps11,sabelfeld-inlining2012} and Jeeves \cite{jeeves2012}
% projects use dynamic techniques to monitor safe execution of information flow policies.
%  Richards et al.\ \cite{FlacJS}   extended this approach by
% incorporating explicit dynamic ownership of objects (and thus of
% capabilities) and policies that may examine the history of objects'
% computations. While these dynamic techniques can restrict or terminate
% the execution of a component that breaches its security policies, they
% cannot guarantee in advance that such violations can never happen.
% While information flow policies are concerned with the flow of objects (and thus also capabilities)
% across the program code, our work is more concerned with the identification of the objects which protect
% the services.

%Compared with all these approaches, our work   focuses on
%\textit{general} techniques for specifying (and ultimately verifying)
%capability policies, whereas these systems are generally much more
%\textit{specific}: focusing on one (or a small number) of actual
%policies. % This seems to be because contemporary object capability
%programming is primarily carried out in JavaScript, but
% There are few

\paragraph{Verification of Dynamic Languages}
A few formal verification frameworks  address JavaScript's highly
dynamic, prototype-based semantics. Gardner et al.\ \cite{Gardner12}
 developed a formalisation of JavaScript based on separation logic
% that they have used
and verified   examples. Xiong and Qin et
al.\ \cite{XiongPhd,Qin11}  worked on similar lines.
% More substantially,
Swamy et al.\ \cite{JSDijkstraMonad}  recently
developed a mechanised verification technique for JavaScript based on
the Dijkstra Monad in the F* programming language.  Finally, Jang et
al.\ \cite{Quark} % have %  managed to provide
developed a machine-checked proof of
five important properties of a web browser --- again similar to our
\prg{any\_code} invariants --- such as
% \textit{``no tab may interfere with
%  another tab''} and 
\textit{``cookies may not be shared across
  domains''} by writing the minimal kernel of the browser in Haskell.
 
% \paragraph{Relational models of trust.}
% Artz and Gil \cite{artz-trust-survey-2007} survey various
% types of trust in computer science generally, although trust has also
% been studied in specific settings, 
% %
% ranging from peer-to-peer systems \cite{aberer-trust-p2p-2001} and
% cloud computing \cite{habib-trust-cloud-2011} 
% to mobile ad-hoc networks \cite{cho-trust-survey-adhocnets-2011}, 
% the internet of things \cite{lize-trust-IoT-2014}, 
% online dating \cite{norcie-trust-online-dating},
% and as a component of a wider socio-technical system
% \cite{cho-trust-sustainable-2013,walter-trust-cloud-ecis2013}. 
% %
% Considering trust (and risk) in systems design, Cahill et al.'s overview
% of the \textsc{Secure} project \cite{cahill-trust-pervasive-2003}
% gives a good introduction to both theoretical and practical issues of
% risk and trust, including a qualitative analysis of an e-purse
% example. This project builds on Carbone's trust model
% \cite{carbone-formal-trust-2003} which offers a core semantic model of
% trust based on intervals to capture both trust and uncertainty in that
% trust. Earlier Abdul-Rahman proposed using separate relations for
% trust and recommendation in distributed systems
% \cite{abdul-rahman-distributed-trust-1998}, more recently Huang and
% Nicol preset a first-order formalisation that makes the same
% distinction \cite{huang-formal-semantics-trust-calculus-2010}.
% Solhaug and St{\o}len \cite{solhaug-trust-uncertainty-2011} 
% consider how risk and trust are related to uncertainties over
% actual outcomes versus knowledge of outcomes.
% Compared with our work, these approaches produce models of trust
% relationships between high-level system components 
% (typically treating risk as uncertainty in trust) 
% but do not link those relations to the system's code. 



% \paragraph{Logical models of trust.}
% \sd{A detailed study of how web-users decide whether to trust appears in \cite{GilArtz}.}
% \sd{Starting with \cite{Lampson92},} various different logics have been used to measure trust in different
% kinds of systems.
% Murray and Lowe \cite{murray10-infoflow} model object capability
% programs in CSP, and use a model checker to ensure program executions
% do not leak authority.
% Carbone et al.\ \cite{carbone-formal-trust-2011}
% use linear temporal logic to model specific trust relationships in service
% oriented architectures.
% Ries et al.\ \cite{habib-trust-CertainLogic-2011} evaluate trust under
% uncertainty by evaluating Boolean expressions in terms of real values
% for average rating, certainty, and initial expectation.
% % Perhaps closer to our work, Aldini
% Aldini \cite{aldini-calculus-trust-IFIPTM2014} describes a temporal logic for
% trust that supports model checking to verify some trust properties.
% Primiero and Taddeo \cite{primiero-modal-theory-trust-2011} have
% developed a modal type theory that treats trust as a second-order
% relation over base relations between
% counterparties. Merro and Sibilio
% \cite{merro-calculus-trust-adhoc-facs2011} developed a trust model for
% a process calculus based on labelled transition systems.
% Compared with our proposal, these approaches use
% process calculi or other abstract logical models of systems, rather
% than engaging directly with the system's code.


\paragraph{Verification of Object Capability Programs}

Dro\-sso\-pou\-lou and Noble \cite{capeFTfJP,capeFTfJP14} have
analysed Miller's Mint and Purse example \cite{MillerPhD} by
expressing it in Joe-E 
% a Java subset without reflection and static
%fields, 
and in Grace \cite{capeFTfJP14}, and discussed the six
capability policies 
% that characterise the correct behaviour of the
% program, 
as proposed in \cite{MillerPhD}.
%We argued that these policies require a novel
%approach to specification, and showed some first ideas on how to use
%temporal logic.
\kjx{not sure how to handle our previous non-publications here:
  ignore most of them and if anyone compalins, claim double-blind priviledge?}
In  an unpublished technical report
\cite{WAS-OOPSLA14-TR}, {they} % Drossopoulou and Noble
sketched a complex specification language, and used it to fully
specify the six policies from \cite{MillerPhD}; % however,
{their} partial formalisation showed that % they allowed
several possible interpretations were possible.  They also uncovered
the need for another four policies and formalised them as well,
showing how different implementations of the underlying Mint and Purse
systems coexist with different policies \cite{capeIFM14},
and have sketched how 
a trust-sensitive 
example (the escrow exchange) could be verified in an open world
\cite{swapsies}. 
In contrast, this work focuses on the semantics of the  \Chainmail\ specification
language and how it can be used to provide holsitic specifications for
robust programs.

%%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% 
%%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% 





