\newcommand{\sophiaPonder}[2][]{\ponders{Sophia}{blue}{#1} \textcolor{blue}{#2}\xspace}
\renewcommand{\sophia}[2][]

\section{Introduction}

Today's complex software has been built 
over decades by combining modules and components of
different provenance and different degrees of trustworthiness, and 
interacts with almost every other program, device, or person.
Modules are useful and robust only if
``bad things will never happen'' (safety), as well as ``good things
will eventually happen'' (liveness)  \cite{Lamport77}. 
 
"Good things happening" is  typically specified formally 
 through triples consisting of a  precondition, a code snippet, and some
 postcondition \cite{Hoare69}.
 For example, if I call the \prg{transfer} function (code snippet) providing the correct 
 password (pre-condition), then some amount will be transferred from my account (post-condition -
 the "good thing").
The precondition is a \emph{sufficient} condition for the code snippet to
make the good thing happen: given the precondition (eg providing the right 
password), executing a
code snippet (eg calling the transfer function) 
is guaranteed to achieve the postcondition (the money is transferred).

Proving adherence to such specifications  poses considerable challenges, esp in the 
context of aliasing, re-entrancy, multithreading, memory models, to name a just a few. 
Such challenges  has been studied intensively over the last  2 decades 
 \cite{BIMutable,objInvars,DenyGuarantee,RealxedC11} -- again just naming a few.
 
 
Our work is concerned with modules' robustness: bad things  will
not happen, no matter the module's client is benign or malicious.
\sophiaPonder[I fear this sentence breaks the flow]
{We go beyond the design by contract approach \cite{Meyer09},  and
cannot rely that a module's client will stick to the module's contract.}
\sophiaPonder[shall we cite Swapsies]{For example, a bank module is robust, if it guarantees that 
in a context where no external agent knows the account's password, the balance of 
that account will not decrease -- such a guarantee allows me to confidently 
pass my bank account into untrusted code, in the expectation of receiving some payment.}
Expressed as a necessary condition, this guarantee says that the 
balance of a bank account will not be reduced, unless an external agent knows
the account's password.
%
% SD Perhaps this sentence should come later
% In this paper we propose how  to specify
%such necessary conditions formally, as well as ways to provide adherence to
%such specifications.
 
 
A multitude of approaches on guarantees that
bad things will not happen have been proposed at different granularity and 
for different languages or calculi. \sophiaPonder[should this appear here?]{Our work is the first to
concentrate on the 
\emph{emergent behaviour} of modules.}  
 
Type systems have been developed for various programming languages 
and give relatively coarse-grained guarantees, \emph{e.g.,} 
 that "message not understood errors" 
will not be thrown \cite{EiffelCook},
or that private methods will not called by external modules \cite{JavaAccess},
or that  no object or method will directly point inside the internal representation of some other object
\cite{ownaliasDONTUSE},
or that race conditions will not arise  \cite{mindori} -- again, just naming a few.

 Information-flow control  systems have been developed for
various calculi and programming languages. Their 
 guarantees are also coarse-grained:  the contents of high security variables cannot
be affected by the values of low security variables \cite{Zdancewic:Myers:01,noninteferenceOS}. 
 
Correspondence assertions are more fine-grained. They were proposed for 
process calculi,  and give guarantees of the form that if one principal
 ever reaches a certain point in the protocol, then some other principal has 
 previously reached some other matching point in the protocol  \cite{correspondence}. 
% SD thought the below was true, but nor think it is not
% Correspondence assertions have also
% been proposed for Javascript. 
A related problem is authorisation policies, which promise that 
certain actions will not be taken on certain objects
unless corresponding  rights had been granted
 \cite{auhtorInDistr}.
 
 
\sophiaPonder[TO WORK ON THIS]{Here lots missing:  talk of  T  of Devfriese et al here ..
 TACAS has 1st order temporal operators to
 accomodate the temporal aspect -- and no reasoning.
 }
 
 The contribution of our paper is twofold: we propose Necessity Specs, to describe such necessary conditions,
 and a Necessity Logic to reason about modules' adherence to such Necessity Specs. 
 

 
Our Necessity Specs allow us to capture \sophiaPonder[need to explain that]{emergent behaviour}.  
Building on ideas from \citeauthor{FASE},  
 we introduce
\textit{necessity specifications} of the following two forms:
%
%
%\hspace{1cm} $\onlyIf {A_1} {A_2} {A_3}$ \\ 
%
%% \begin{lstlisting}[mathescape=true, language=chainmail, frame=lines]
%% $\onlyIf {A_1} {A_2} {A_3}$ 
%% \end{lstlisting}
%
\begin{lstlisting}[mathescape=true, language=chainmail, frame=lines]
                   from ${A_1}$ to ${A_2}$ onlyIf ${A_3}$ 
                    
                   from ${A_1}$ to ${A_2}$ onlyThrough ${A_3}$
\end{lstlisting}
%
The former says that  a change from a current state satisfying $A_1$ to a future
state satisfying $A_2$ (i.e.\ an effect) is possible only if the necessary condition
$A_3$ holds in the current state
%
(i.e.\ $(A_1 \wedge \Diamond A_2) \longrightarrow A_3$).
The latter says that a change from a current state satisfying $A_1$ to a future
state satisfying $A_2$  is possible only if the necessary condition
$A_3$ holds in some intermediate state.\sophiaPonder[not sure we need to have the latter, 
and do not have temp logic form of it]{}.
Unlike \citeauthor{VerX} or \citeauthor{FASE}
which employ general temporal operators, 
the necessity operators $\onlyIf {\_} {\_} {\_}$  and $\onlyThrough {\_} {\_} {\_}$
are second class, and may nor appear in the assertions $A$.
%support necessity specifications with this explicit
% ``$\onlyIf {A_1} {A_2} {A_3}$'' syntax
%
%and concomitant specialised inference system.
%
%
Our assertions $A$ support the usual expressions about program state
%(e.g. \prg{x.f > 3}),
 logical connectives and quantifiers, 
%(e.g. $\wedge$, $\forall$), 
and additional predicates
to capture \textit{provenance} (whether an object $o$'s definition is
$\internal{\texttt{o}}$ or $\external{\texttt{o}}$) to the current
module, and \textit{permission} \cite{miller-esop2013} (whether an
object $o$ has direct access to another object $o'$:
$\access{\texttt{o}}{\texttt{o'}}$).
 
The Necessity Logic is based on three main ideas: 
First, Assertions may be module-internal, ie
their validity may only be affected by module-internal calls. 
Second, based on the classical specs of methods 
\sophiaPonder[here mention Birkedahl recent]{we can infer per-method 
necessity specs}.
A special logic allows us to combine per-method necessity specs into per
module necessity specs.

 
%The below is good and perhaps we shpuld use it
% The challenge here is twofold: How do we specify the bad things we are
%concerned about, and how do we prove that the bad things we've
%specified do not happen?  These challenges are difficult because we
%cannot refer to just one component of a software system.  A sufficient
%specification can deal with a single component in isolation --- a
%single function for pre- and postconditions; a single class or data
%structure for invariants. A necessary specification, however, must
%provide guarantees which encompass the software system in its
%entirety, and constrain the emergent behaviour of all its components,
%for an open system, all possible sequences of API invocations.
% 
% 
%
% 
%The importance of distinguishing between sufficient and necessary
%specifications of various kinds has a long history in Computer
%Science.
% 
%  Type systems ensure entire classes of bad things can't
%happen, preserving execution even if memory structures are greatly
%corrupted \cite{Rinard03}.
%%
%More recently, \citeauthor{ddd} and \citeauthor{sandbox} with their robust safety and
%\citeauthor{FASE} with their holistic systems have tackled open world systems to prevent bad things from happening from untrusted code.
%\citeauthor{ddd} use techniques from security to ensure \jm[]{there} isn't undesirable leakage, \citeauthor{sandbox} build a sandbox and have a sophisticated type system to protect it and \citeauthor{FASE} have
%necessary conditions, which they expressed through temporal
%operators.

In the next section, (\S\ref{s:outline}),  we outline our approach in terms of a motivating example.
This example shows, among others, that the specification needs to talk about the module as a whole,
without making reference to the individual methods in that module.
Moreover, while a module may adhere some such a necessity spec, an
augmented version may no longer adhere. 
 

\subsection{Contributions}

The contributions of this paper are as follows:
 
 \begin{enumerate}
 \item
\Chainmail, a language to
express necessity specifications (\S\ref{s:semantics});
 \item
%a logic for proving a module's adherence to its
%necessity specifications (\S\ref{s:inference});
%% This logic builds on top of classical pre- post- conditions.
\begin{description}
\item [(a)]
{a logic for raising assertion encapsulation and classical Hoare specifications
to necessity specifications for any single module interaction (\S\ref{s:module-proof});}
\item [(b)]
 {a logic for raising single step necessity specifications for a module to an arbitrary number of steps
and thus proving module adherence to necessity specifications for any execution, and any combination of module interactions, i.e. emergent behavior (\S\ref{s:emergent-proof});}
%% This logic builds on top of classical pre- post- conditions.
\end{description}
\item
  a mechanised {Coq} proof of soundness of the logic (\S\ref{s:soundness});
\item
  a  {mechanised Coq} proof that % the bank account 
  our example obeys the necessity
  specification (\S\ref{s:examples}).
\end{enumerate}


\noindent Finally we place necessity specifications into the context
of related work (\S\ref{s:related}) and conclude (\S\ref{s:conclusion}).
The Coq proof of the logic appears in the
supplementary material.








