        
%% This is a very scrappy first draft of a related work section ---
%% hopefully someone will at least edit it, fix typos, and remove this
%% sentence! It is Sophia's text from the introduction, plus stuff from
%% previous papers (notably the TOSEM rejected draft, including verona,
%% necessity, holistic) and various other grant application whot I wrote.


%% \paragraph{Behavioural Specification Languages} 

%% \citet{behavSurvey2012} provide an excellent survey of
%% contemporary specification approaches.  With a lineage back to Hoare
%% logic \cite{Hoare69}, Meyer's Design by Contract \cite{Meyer97} was the
%% first popular attempt to bring verification techniques to
%% object-oriented programs as a ``whole cloth'' language design in
%% Eiffel.  Several more recent specification languages are now making
%% their way into practical and educational use, including JML
%% \cite{Leavens-etal07}, Spec$\sharp$ \cite{BarLeiSch05}, Dafny
%% \cite{dafny} and Whiley \cite{whiley15}.
%% . Our approach builds upon
%% these fundamentals, particularly Leino \& Shulte'sj
%% %\kjx{and Naumann's} 
%% formulation of
%% two-state invariants \cite{usingHistory}, and Summers and
%% Drossopoulou's Considerate Reasoning \cite{considerate}.
%% %
%% In general, these approaches are within the setting of a closed
%% system, where modules can be trusted to co{\"o}perate. In this paper
%% we aim to
%% % illustrate the kinds of techniques required
%% work
%% in an open system where many modules are unknown by, or even actively
%% antagonistic to the system as a whole: and even worse, where
%% known / trusted / internal code must interact with unknown / untrusted
%% / external code, both making outgoing calls into the unknown components,
%% and receiving incoming calls from the unknown components --- even
%% callbacks, i.e.\ incoming calls back into internal components while
%% those internal components executions are themselves suspending during
%% the outgoing calls\ldots


%% Most specification langauges and verification systems assume
%% a close world: that all components of a system are known, accesible,
%% scruitable, verifiable, and indeed have been verifiably 

In an open world, public interfaces of software components can be
called in any order at any time. 
Since open calls may in turn call any number of other 
methods, it is crucial to prove that \taming of effects is preserved
by the module's \emph{emergent} behaviour.
%
%% , \ie any series of incoming
%% external calls, intertwined with internal calls to internal methods,
%% and then outgoing external calls either to other external objects (if
%% we're lucky) or callbacks into the internal objects that are currently
%% Asuspended waiting for the results of the external call (if we're not).
%
%
%% \citet{Rinard03} first made clear how type systems express
%
%% properties that hold for all program executions: type safety assures
%% that e.g.\ typesafe execution can continue indefinitely, even if the
%% data being processed, memory layouts, or communications into and out
%% of a program are completely randomised. The point of program
%% verification, of course, is to give rather more semantic guarantees.
%
%
%
%\footnote{Properties which rely on the type system, are of course preserved,%%  but what about more semantic properties?}
%% \textbf{xxx-OOPSLA-22-workshop} SOPHIA WHAT IS THIS REFERENCE? does this by
%% replacing an open call though an unbounded number of calls to a
%% module's public method.
%
To address this problem, 
\citet{FASE}  proposed holistic specifications which take an external
perspective across one or more modules.
%% (compared with pre- and post- conditions that supply internal
%% specifications for individual method implementations, and class,
%% monitor, or module invariants that make internal specifications for all
%% the methods in a single class, monitor, or module.
\citet{OOPSLA22} builds upon this work, offering a specification
language based on necessary conditions, rather than sufficient
conditions as in most specification languages, and a Hoare logic to 
that can prove modules  adhere to such specifications. Unfortunately
neither of these systems support any kind of external calls.

%% --- rather
%% they rely on simplistic type-based module confinement
%% \cite{ownership-confinement-jacm2004,confined-toplas2007} which
%% prevents any kind of external references or external calls, either
%% outgoing or incoming.

Key to these approaches is the goal of proving properties that must
hold across every execution. The semantics we use in this paper,
defined in section~\ref{def:necessity-semantics}, are based on
primitive classical assertions that characterise individual states.
%% The semantics of the underlying language require those
%% specifications to hold over all states that can possible arise from
%% any execution of a module beginning from a defined initial state.
%
Hyper-Hoare Logic \cite{hyper-hoare-pldi2024}, and Compositional
HyperSafety Logic \cite{compositional-hypersafety-oopsla2022} embody
an alternative formulation of the problem. These ``hyper-logics''
express 
programs' hyper-properties in terms of hyper-assertions
over sets of states.
%% , rather than e.g.\ our classical approach
%% where assertions range over an individual state, or at most two
%% causally liked states.
Hyper-logics increase the power of the specification language although
at the cost of making the language more complex.















%\paragraph{Defensive Consistency}

%cute but wrong.
%To misparaphrase Tolstoy, secure systems are all alike;
%every insecure system is insecure in its own way
%\cite{WikipediaAnnaKareninaPrinciple}.

In an open world, we cannot rely on the kindness of strangers: rather
we have to ensure our code is correct regardless of whether it
interacts with friends or foes.
Attackers 
\textit{``only have to be lucky once''} while secure systems 
\textit{``have to be lucky always''} \cite{IRAThatcher}.
% SD 
Miller \cite{miller-esop2013,MillerPhD} defines the necessary approach
as \textbf{defensive consistency}: \textit{``An object is defensively
  consistent when it can defend its own invariants and provide correct
  service to its well behaved clients, despite arbitrary or malicious
  misbehaviour by its other clients.''}  Defensively consistent
modules are hard to design,  write,  understand, and
verify: but
% they have the great advantage that
make it much
easier to make guarantees about systems composed of multiple components
\cite{Murray10dphil}.







\citet{CassezFQ24} illustrate one approach to ensuring defensive
consistency while handling external calls.
%in the context of the Dafny verifier.
Given that 
%The key idea is that
external callbacks
%(outgoing external calls that themselves make re{\"e}ntrant incoming calls)
are
necessarily restricted to a module's interface,
% to be verified, 
external callsites are replaced 
with a
generated \texttt{externalcall()} method that 
nondeterministically invokes
%
%issues a sequence of callsf to the module's\
that 
interface, 
ensuring that any 
%This means that in order
%To verify their code, programmers
%must ensure that no
sequence of external calls must maintain the
invariants.
%
%and provide enough information for Dafny to accept that proof.
%
\citet{iris-wasm-pldi2023}'s Iris-Wasm is similar.
%%similar to Cassez which is why this is here 
%% to enforce 
%% modularity in a formal model of WASM built in Iris.
WASM's
%% has the
%% advantage that its
modules are very loosely coupled: a module
%instantiation has its own
has its own byte memory
(stores only bytes) 
and object table
(stores opaque references to closures and external handles).
%
%% that
%% are generalltion not shared between modules; byte memory stores bytes,
%% and object tables
%
Iris-Wasm ensures models 
can only be
modified via their explicitly exported interfaces.
%
Likewise, Rich-Ethereum \cite{rich-specs-smart-contracts-oopsla2021}
relies on Ethereum%intrinsic modularity:
contract's fields being instance-private
%% (as in Smalltalk, each object can only
%% assign to fields which are its very own).  ,
and unaliased, while
%intercontract aliasing is prohibited
%by the underlyiung infrastructure.
a per-contract ``finished'' flag
%, effectively a latch obeying a
%5``write-once-after-initialisation'' modelled
manages callbacks and termination.
%
%
%
%
%
Scilla \cite{sergey-scilla-oopsla2019}
is a minimalistic functional alternative to Ethereum,
based on restricted actor-style
communication, restricting recursion, and ensuring termination,
which has demonstrated that popular Ethereum
contracts avoid common contract errors.
%type errors, out-of-gas resource failures, and
%preservation of virtual currency. 
%
All these appproaches depend on
% both rely on significantly more
environments which support encapsulation:
%% impmore lementations than our take on the open world, where
%% interobject references are unconstrainted.
%% In our approach,
we show how unrestricted references to mutable objects can be protected
%by the emergent
%behaviour of a module's code, i.e.\
by programmer discipline,
and that disciplline trusted, then verified.

%% albeit a discipline reifird with our protection constructs and
%% consequently succeptible to verificaiton.


%\paragraph{Verification of Object Capability Programs}


%%\paragraph{Object Capabilities and Sandboxes.}



%% {{\em Capabilities} as a means to support the development of concurrent and distributed system  were developed in the 60's
%% by Dennis and Van Horn \cite{Dennis66}, and were adapted to the
%% programming languages setting in the 70's \cite{JamesMorris}. 
%% {\em Object capabilities} were first introduced~\cite{MillerPhD} in the early 2000s},
%%  and many recent % work attempts to manage
%% studies manage
%% to verify  safety or correctness of object capability programs.


\citet{Murray10dphil} made the first attempt to formalise defensive
consistency, based on counterfactual causation~\cite{Lewis_73}
to tolerate interacting with any untrustworthy object,
although
%
%% an object is defensively
%% consistent when the addition of untrustworthy clients cannot cause
%% well-behaved clients to be given incorrect service.
%
%% Murray formalised
%% defensive consistency very abstractly, over models of (concurrent)
%% object-capability systems in the process algebra
%% CSP~\cite{Hoare:CSP},
%
without a specification language for describing effects
(i.e.\ when an object is correct).
%(i.e.\ what it means for an object to be correct).
%% , such as what
%% it means for an object to provide incorrect service.  Both Miller and
%% Murray's definitions are intensional, describing what it means for an
%% object to be defensively consistent.
%
%
Google's Caja \cite{Caja} applies
(object-)capabilities \cite{Dennis66,JamesMorris,MillerPhD}, 
sandboxes, proxies, and wrappers
 to limit components'
access to \textit{ambient} authority.
% --- that is, capabilities that
%can be obtained from the wider environment, rather than being granted
%to a component explicitly.
Sandboxing has been validated
formally % Maffeis et al.\
\cite{mmt-oakland10};
%develop a model of
%JavaScript, demonstrate that it obeys two principles of
%object capability systems
%  (``connectivity begets connectivity'' and
%``no authority amplification''), and then % uses these principles to
%and show  how untrusted applications can be prevented from interfering with
%the rest of the system.
%and 
recent languages % and web systems
\cite{CapJavaHayesAPLAS17,CapNetSocc17Eide,DOCaT14} including Newspeak
\cite{newspeak17}, Dart \cite{dart15}, Grace \cite{grace,graceClasses}
and Wyvern \cite{wyverncapabilities}
have adopted
%adopt
object
capabilities.




%% %% \citet{capeFTfJP,capeFTfJP14} have
%% %% analysed \citet{MillerPhD}'s Mint and Purse example 
%% %% % SD Chope details by
%% %% % expressing it in Joe-E 
%% %% % a Java subset without reflection and static
%% %% %fields, 
%% %% %and in Grace \cite{capeFTfJP14}, 
%% %% and discussed the six
%% %% capability policies 
%% %% % that characterise the correct behaviour of the
%% %% % program, 
%% %% as proposed by \citet{MillerPhD}.
%% %% %We argued that these policies require a novel
%% %% %approach to specification, and showed some first ideas on how to use
%% %% %temporal logic.
%% %% %  an unpublished technical report
%% %% \citet{WAS-OOPSLA14-TR} %, {they} % Drossopoulou and Noble
%% %% sketched a  specification language,  \sd{used}  it to  
%% %% specify the six policies from \cite{MillerPhD}, % however,
%% %% %{their} partial formalisation showed that % they allowed
%% %% \sd{showed} that several possible interpretations were possible, %.  They also 
%% %% \sd{and} uncovered
%% %% the need for another four further policies.
%% %% %  and formalised them as well, showing how different implementations of the underlying Mint and Purse
%% %% % systems coexist with different policies \cite{capeIFM14},
%% %% They also
%% %%   sketched how 
%% %% a trust-sensitive 
%% %% example (the escrow exchange) could be verified in an open world
%% %% \cite{swapsies}. 
%% %% % In contrast, our work focuses on the semantics of the  \Chainmail\ specification
%% %% % language and how it can be used to provide holistic specifications for
%% %% % robust programs.
%% %% %% \sd{Their work does not support the concepts of control, time, or space, as in \Chainmail,
%% %% %%   but it offers a primitive expressing trust.}

 
%% Some more recent work is particularly relevant to proof of properties
%% of programs employing object capabilities in this open world.

% SWASSEY 18 garg dreyer

\citet{ddd}  designed OCPL, a logic
%% for object capability patterns, that supports specifications and
%% proofs
%for object-oriented systems in an open world.  
% The key idea here is to 
%\sd{They} % say it simpler
that %draws on verification techniques for security and
%information flow: separating
separates internal implementations (``high values'')
%which must not be exposed to attacking code)
from interface objects
(``low values'). %
%which may be exposed).
OCPL supports defensive
consistency % (Swasey et al.\ use 
%(\sd{they} use the term
(called``robust safety'' after the
security literature \cite{Bengtson})
by ensuring
%via a proof system that ensures
low values can never leak high values,a % to external attackers. 
%\susan{How does this imply that high values can be exposed?}
%\james{typo fixed: it's LOW values that can be exposed}
%% This means that low values \textit{can} be exposed to external code,
%% and the behaviour of the system is described by considering attacks only
%% on low values.  %OCPL is a program logic, and Swasey
%% \sd{They}
and 
%use that logic to
prove %a number of
object-capability patterns, such as
sealer/unsealer, caretaker, and membrane.
%
%This work was then developed to prove the memory properties of Rust in
%the
%
RustBelt \cite{RustBelt18}
developed this approach to prove Rust memory safety,
via the IRIS automated
separation logic \cite{iris-jfp2018},
%
%
%RustBelt was combined with the
and was combined 
with the RustHorn  %that uses classical logic 
%\se{SUSAN: doesn't it use Horn Clause Logic? or Constraint Horn
%Clause Logic?} \
(which verifies the safe subset of Rust \cite{RustHorn-toplas2021}),
producing RustHornBelt \cite{RustHornBelt-pldi2022} that verifies
both safe and unsafe Rust programs.% in classical first-order logic.
Similar techniques were extended to C \cite{RefinedC-pldi2021}.
%note that while C is not ``memory-safe'', neither is unsafe Rust.
%Compared to the work we present in this paper,
While these projects 
verify ``safe'' and ``unsafe'' code, 
%
%both projects have
%rather different interpretations of ``safety''.
the distinction is about memory safety:% only:
%both kinds of code are veridied.
%
%their ``unsafe'' code does 
%
%code that is not known to the verification system,
%is trusted, and indeed will be verified, but for which the language
%does not enforce its characteristic memory constraints,
%
whereas all our code is ''memory safe''
%(garbage
%collected, object capabiltiies cannot be forged)
but unsafe / untrusted code
is unknown to the verifier.
%, and may be directly antagonistic to the
%overall properties of the system.
%
%
\citet{schaeferCbC} also adopted
an information-flow approach to ensure confidentially by construction.

% taken a similar approach to Swasey,
% adding support for
%% \sd{added}  support for information-flow security % in a setting 
%% \sd{using} refinement to ensure correctness (in this case confidentiality) by
%% construction. 
% Although designed to support
% confidentialty, it seems likely that the information-flow guarantees
% could also be used to ensure robustness.  





% devrise birkedal S&P 2016; 
 
%\citet{dd}  have deployed
%   \sd{powerful} %rather more complex
%  theoretical techniques to address similar problems:  % Devrise et al.\ 
%  \sd{They} show how
\citet{dd} deploy
step-indexing, Kripke worlds, and representing objects
as public/private state machines % with public and private transitions
%can be used to
%reason about % object-oriented programs in general.
%\sd{object capabilities}.
to model 
%Devriese have demonstrated
%solutions to a range of 
%including the
problems including the 
DOM wrapper and a mashup application.
% Although the formal techniques are much more sophisticated than we
%apply here, and consequently 
% not true can e.g.\ reason about recursion where we
%cannot, there are some similarities, e.g.\ with the 
\sd{Their} distinction
between public and private transitions %being related 
\sd{is similar} to our
distinction between internal and external objects.
%
%
This stream of work has culminated in VMSL, a Iris-based seperation logic for
virtual machines to assure defensive consistency
\cite{vmsl-pldi2023}
(sadly not a logic for VAX/VMS systems),
%
%``robust safety'' (more or less defensive consistency),
%
and Cerise, which
uses Iris invariants to support proofs of programs
with outgoing calls and callbacks,
on capability-safe CPUs \cite{cerise-jacm2024},
via
%relatively low-level proof
problem-specific proofs in Iris's logic.
% variant of seperation logic. 
%
Our work differs from Swasey, Schaefer's, and Devriese's work in that
% \citet{ddd} and \citet{schaeferCbC} 
they are primarily concerned \sd{with} %about
ensuring defensive consistency, 
while we focus on specifications
% of programs' behaviour,
and proofs more widely.
% that programs can meet those specifiations.
%% \Chainmail\ abstracts away from any mechanism via
%% an external predicate. 
%
%
%% %% \sd{Swasey and Schaefer use powerful mathematical techniques, such as
%% %% Kripke worlds and step-indexing  
%% %% which  the users need  to understand in order to write their specifications,
%% %% while \Chainmail users only need  to understand  first order logic and 
%% %% their additional holistic operators.}
%
%
% While \Chainmail's $\Using{}{}$ is related to Banerjee
% and Naumann's region sets, the assertion languages here are mostly
% traditional (extensions of) Hoare logics --- Swasey et al.\ build on a
%concurrent separation logic. 
%% \sd{ Finally, none of these systems offer the kinds of
%% holistic assertions addressing control flow, change, or temporal
%% operations that are at the core of \Chainmail's approach.
%% }


% Scilla's semantics are defined formally, but have not yet been represented in a
% mechanised model.

%% \kjx{NPChecker \cite{NPcheckerOOPSLA19} analyses Ethereum smart
%% contracts to detect bugs related to nondeterministic
%% execution. NPChecker undertakes an information flow
%% analysis to detect potential read-write hazards
%% particularly reentrancy and ordering dependencies.
%% \textbf{We don't do concurrency. Do we need this one? I don't think so}
%% }




The VerX tool can verify
specifications for solidity contracts automatically \cite{VerX}.
VerX's specification language is based on
temporal logic, 
but only within a past modality, while e.g.\ \citet{OOPSLA22} has both past
and future modalities.
%% VerX specifications can also include
%% predicates that 
%% model the current invocation on a contract (similar to \Chainmail's
%% ``calls''), can access variables, and compute sums (only) over
%% collections.
%\Chainmail\ is strictly more expressive as a
%specification language,
%% including quantification over objects and sets
%% (so can compute arbitrary reductions on collections) and of course
%% specifications for permission (``access''), space (``in'') and
%% viewpoint (``external'')
%% which have no analogues in VerX. 
%% Unlike
%
%Unlike
%
%our work,
%
%% %% VerX %includes a practical tool that
%% %% has
%% %% been used to verify a hundred properties across case studies of
%% %% twelve Solidity contracts.
%\textbf{(ideally also say something about proof status)}}
%
%
%
Unlike Cerise, which handlew callbacks, VerX
is restricted to ``effectively call-back free'' programs
\cite{Grossman,relaxed-callbacks-ToDES},
delaying any callbacks until the
incoming call to the internal object has finished,
turning a callback
%(a call invoked to handle an outoing external call)
into a more straightforward  incoming call. 
%
\textsc{ConSol} \cite{consolidating-pldi2024}
provides a specification langauge for smart contracts,
checked at runtime \cite{FinFel01},  with case studies 
showing it could prevent some famous smart contract errors.
%%
%%  language, based around classical pre- and post-conditions and
%% a special higher-order treatment of the blockchain addresses used in
%% smart contracts. The project analyses twenty well-known erroneous
%% contracts and claims that ConSol specifications would prevent those
%% errors.
SCIO* \cite{secure-io-fstar-popl2024} implemented in
%the dependentlytyped language
F*
%offers another approach: the system
supports both
verified and unverified code: unverified code 
corresponds to our external modules. 
Like \textsc{ConSol}, SCIO* uses runtime checks
(higher-order contracts and reference monitors)
to ensure unverified
code cannot break verified code.
Both \textsc{Consol} and SCIO* are 
similar to gradual verification techniques 
\cite{gradual-verification-popl2024,Cok2022} that
insert dynamic checks between verified and unverified code.



% \paragraph{Incorrectness Logic}

O'Hearn's Incorrectness Logic
\cite{IncorrectnessLogic}
draws on
Reverse Hoare Logic \cite{reverseHoare}
to reason about the presence of bugs, rather than their absence.
Incorrectness Logic ensures all states that satisfy a
postcondition are reachable from the precondition,
excluding false negatives.
%
Our work is based on correctness rather than incorrectness,
and 
differs from Hoare and Incorrectness Logics
by tolerating interactions between verified code and
untrusted, unknown, potentially antagonistic components.


%% which require specifications of entire closed systems,
%% with the ability to specify open systemss that support incoming calls
%% out of untrusted components, outgoing calls back into untrusted
%% components, and even callbacks where
%% our verified modules call out to unknown and untrusted components,
%% which then call back into our verified and trusted components.


% SD chopped as did not like
%As with Swasey et al.\ this work does not provide a holistic
%assertion language like \Chainmail.
% SD Chopped, as it sounds as if their is not real code, which is debatable
% and what is an extensional framework? they would say that theirs is too.
%In contrast, \Chainmail\ is
%meant for describing and reasoning about real code, and we provide an
%expressive, extensional framework for evaluating defensive consistency
%in actual open systems.
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%
%%


%% %Finally, 
%% \sd{Our} work is also related to the causal obligations in Helm et
%% al.'s behavioural contracts \cite{helm90}. Causal obligations allow
%% programmers to specify e.g.\ that whenever one object receives a
%% message (such as a subject in the Observer pattern having its value
%% changed) that object must send particular messages off to other objects
%% (e.g.\ the subject must notify its observers). \Chainmail's control
%% %SD: not "control flow"
%%  operator % (`$\Calls{\_} {\_} {\_} {\_} $) 
%%  %allows  programmers to make
%%  \sd{supports}  similar specifications, (e.g. 
%%  ${\Calls{\_}  {\prg{setValue}} {\prg{s}} {\prg{v}}}  \rightarrow \Future{\Calls{\prg{s}}{\prg{notify}}{\prg{s.observer}}{\prg{v}}}$ --- when a subject receives a \prg{setValue} method,
%%   it must ``forward'' those messages to the observer.


%%NOTES:
%% the other thing this section needs to do, particularly with Devrise, is to lay out precisely the way our work is more limited than theirs:
%% (Swasey, I'm more and more convinced, is just ownership-via-a-proof-system) 
%% we don't step-index, don't have logical relations, etc: what do we lose by NOT having those things
%% (or what do we gain by having those things...

%% The "deep" comparison with Swasey and with Devirese (and also
%% information flow control and temporal logics) needs to say why these
%% works are not as good (expressive? easy to understand?) as ours.
%% Currently the Related work just mentions them, but does not answer the
%% question as to why our work is important when theirs already has been
%% published.




%% *Difference between Spec Languages and Chainmail*  One way to tackle
%%  this would be to enumerate which elements of Chainmail appear at
%%  other works, which do not, and claim that Chainmail’s novelty is the
%%  good combination of these elements


%% Eg: reflection about contents of stack and heap (in classical Hoare
%% Logics), two state assertions (JML etc), invariants (Hoare and Meyer),
%% internal/external (Liskov?, Noble et al,modules in Neumann and also
%% O’Hearn), time (temporal logic, but they do not have the other stuff),
%% Control (none?), Space (in Sep. logic, and in effects, buyt the
%% meaning is different), Permissions (our earlier work, and less
%% flexible approaches such as owenrship types and perhaps also
%% oinformation flow control), Authority (effect systems and modifies
%% clauses, and perhaps also Bierman&Parkison abstract predicates, but
%% there it is tied to pre-post conditions.


%% Also, point out difference between our invariants and Hoare
%% triples. Subtle and needs thinking







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Neither effort addresses specification languages for security and
%% robustness, provides Hoare logics to reason about object-capability
%% programs.

%% , model protocols that dynamically ascribe trust
%% \cite{swapsies,lefthand} or quantify the damage an untrustworthy
%% object can do.






% \kjx{History-Based Specification and Verification of Scalable
%  Concurrent and Distributed Systems --- ICFEM15}


% \paragraph{Specifying Design Patterns}
% Techniques for specifying Design Patterns go back at least to 
% Helm's contracts \cite{Helm92}.

% more importantly: work on formalisation of design patterns.
% (again look at JC grant, even if refs are 5 years old)
% let's be shameless here...



% This search is similar to the quantification over
% potential code snippets in our model.
% The problem posed by the Escrow example is that it establishes a two-way
% dependency between trusted and untrusted systems --- precisely the
% kind of dependencies these techniques prevent.

% %These approaches are all based on static analyses.
%  The WebSand
% \cite{flowcaps11,sabelfeld-inlining2012} and Jeeves \cite{jeeves2012}
% projects use dynamic techniques to monitor safe execution of information flow policies.
%  Richards et al.\ \cite{FlacJS}   extended this approach by
% incorporating explicit dynamic ownership of objects (and thus of
% capabilities) and policies that may examine the history of objects'
% computations. While these dynamic techniques can restrict or terminate
% the execution of a component that breaches its security policies, they
% cannot guarantee in advance that such violations can never happen.
% While information flow policies are concerned with the flow of objects (and thus also capabilities)
% across the program code, our work is more concerned with the identification of the objects which protect
% the services.

%Compared with all these approaches, our work   focuses on
%\textit{general} techniques for specifying (and ultimately verifying)
%capability policies, whereas these systems are generally much more
%\textit{specific}: focusing on one (or a small number) of actual
%policies. % This seems to be because contemporary object capability
%programming is primarily carried out in JavaScript, but
% There are few

 
% \paragraph{Relational models of trust.}
% Artz and Gil \cite{artz-trust-survey-2007} survey various
% types of trust in computer science generally, although trust has also
% been studied in specific settings, 
% %
% ranging from peer-to-peer systems \cite{aberer-trust-p2p-2001} and
% cloud computing \cite{habib-trust-cloud-2011} 
% to mobile ad-hoc networks \cite{cho-trust-survey-adhocnets-2011}, 
% the internet of things \cite{lize-trust-IoT-2014}, 
% online dating \cite{norcie-trust-online-dating},
% and as a component of a wider socio-technical system
% \cite{cho-trust-sustainable-2013,walter-trust-cloud-ecis2013}. 
% %
% Considering trust (and risk) in systems design, Cahill et al.'s overview
% of the \textsc{Secure} project \cite{cahill-trust-pervasive-2003}
% gives a good introduction to both theoretical and practical issues of
% risk and trust, including a qualitative analysis of an e-purse
% example. This project builds on Carbone's trust model
% \cite{carbone-formal-trust-2003} which offers a core semantic model of
% trust based on intervals to capture both trust and uncertainty in that
% trust. Earlier Abdul-Rahman proposed using separate relations for
% trust and recommendation in distributed systems
% \cite{abdul-rahman-distributed-trust-1998}, more recently Huang and
% Nicol preset a first-order formalisation that makes the same
% distinction \cite{huang-formal-semantics-trust-calculus-2010}.
% Solhaug and St{\o}len \cite{solhaug-trust-uncertainty-2011} 
% consider how risk and trust are related to uncertainties over
% actual outcomes versus knowledge of outcomes.
% Compared with our work, these approaches produce models of trust
% relationships between high-level system components 
% (typically treating risk as uncertainty in trust) 
% but do not link those relations to the system's code. 



% \paragraph{Logical models of trust.}
% \sd{A detailed study of how web-users decide whether to trust appears in \cite{GilArtz}.}
% \sd{Starting with \cite{Lampson92},} various different logics have been used to measure trust in different
% kinds of systems.
% Murray and Lowe \cite{murray10-infoflow} model object capability
% programs in CSP, and use a model checker to ensure program executions
% do not leak authority.
% Carbone et al.\ \cite{carbone-formal-trust-2011}
% use linear temporal logic to model specific trust relationships in service
% oriented architectures.
% Ries et al.\ \cite{habib-trust-CertainLogic-2011} evaluate trust under
% uncertainty by evaluating Boolean expressions in terms of real values
% for average rating, certainty, and initial expectation.
% % Perhaps closer to our work, Aldini
% Aldini \cite{aldini-calculus-trust-IFIPTM2014} describes a temporal logic for
% trust that supports model checking to verify some trust properties.
% Primiero and Taddeo \cite{primiero-modal-theory-trust-2011} have
% developed a modal type theory that treats trust as a second-order
% relation over base relations between
% counterparties. Merro and Sibilio
% \cite{merro-calculus-trust-adhoc-facs2011} developed a trust model for
% a process calculus based on labelled transition systems.
% Compared with our proposal, these approaches use
% process calculi or other abstract logical models of systems, rather
% than engaging directly with the system's code.































% % % % % % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %
% \paragraph{Guarantee Reasoning}

Rely-Guarantee
\cite{relyGuarantee-HayesJones-setss2017,relyGuarantee-vanStaden-mpc2015}
and Deny-Guarantee \cite{DenyGuarantee} %reasoning techniques
distinguish between assertions guaranteed by a thread, and those a
thread can reply upon. % (rely-guarantee)% or actions denied to all other
%threads (deny-guarantee, where the ``deny'' condition limits access to
%some state to a particular thread, i.e.\ a thread can rely that other
%threads will not write to the denied state).
%}
Assume-guarantee
reasoning, especially circular
assume-guarantee  \cite{circular-assume-guarantee-fm2015} evinces
% another commonality with our work here:
the main reason callbacks
are hard to handle: circular control flow can lead
all too easily towards circular reasoning.
%%%
Our Hoare quadruples are (roughly) Hoare triples plus 
%that we use in our work are clearly related to
the ``guarantee'' portion of rely-guarantee.
When a
specification includes a guarantee, that guarantee must be maintained
by every ``atomic step'' in an execution
\cite{relyGuarantee-HayesJones-setss2017}, rather than just at method
boundaries as in visible states semantics
\cite{MuellerPoetzsch-HeffterLeavens06,DrossoFrancaMuellerSummers08,considerate}.
%Liquid information flow \cite{liquid-infoflow-icfp2020} and liquid
%resource types \cite{} are likewise similar to the work in this paper.
%
In concurrent reasoning, % the original domain of Rely- and
%Deny-Guarantee reasoning,
this is because shared state may be accessed
by another co{\"o}perating thread at any time:
%not just outside method
%execution boundaries:
while in our case, it is because unprotected
state may be accessed by an untrusted component within the same
thread.  Guarantees correspond to our
properties that must be preserved by all code linked to the current
module. Deny-guarantee assumes
co{\"o}peration:
%composition is legal only if threads adhere to their guarantees,
while we use these ``guarantees'' precisely to
ensure our code can interoperate safely with external untrusted code.
%irrespective of whatever the untrusted code does.

% % % % % % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %% % % %














%%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% 
%%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% 


%\paragraph{Protection vs.\ Ownership}

Finally it is interesting to compare our approach to tamed effects
with Ownership Types 
\cite{simpleOwnership,existOwn}
and related systems that 
enforce  encapsulation boundaries
to protect internal implementations
\cite{ownalias,NobPotVitECOOP98}.
Banerjee and Naumann demonstrated that by
ensuring confinement, ownership
systems can enforce representation independence (a property close to
defensive consistency) some time ago \cite{Banerjee:2005}.
%
Ownership is central to Rust's memory safety
\cite{RustPL2,RustBelt18}, and earlier supported several approaches
to heap analyses \cite{PotterNC98,HillNP02,MitECOOP06} and
program verification
\cite{BoyLisShrPOPL03,hypervisor} including Spec$\#$
\cite{BarLeiSch05,BarDelFahLeiSch04} and universes
\cite{DieDroMue07,DietlMueller05,LuPotPOPL06},
Borrowable Fractional Ownership \cite{borrow-fract-vmcai2024},
and recently integrated into OCAML \cite{ocaml-ownership-icfp2024,funk-ownership-oopsla2024}.

%% By enforcing encapsulation, \sd{all} % used to say both
%% these approaches share similarity with techniques such as
%% ownership types 
%% which also




Ownership ensures that access to an object's \textit{owned} 
subcomponents is mediated via their owner.
Compared to our \textit{protected} capabilities,
owned capabilities are owned with respect to all
modules in the system, 
while protected capabilites are protected relative to some
protecting module,
Conversely, we can characterise ownership as
protection taming \textit{all} references to an object: in practice,
that requires the capability we are protecting is unique at the time
protection is established: \textit{ownership $==$ protection $+$
  uniqueness}.  This relationship presents several potential avenues
for further work: first, where we ensure protection via
a Hoare logic,
weakening some 
of ownership's guarantees may be able to ensure protection via a
straightforward type-based approach.
Second,  tightening some
rules in our current Hoare logic (e.g.\ Def. \ref{def:chainmail-protection-from})
may lead to a native  Hoare logic of ownership.
Third, other recent approaches such as 
%
%% Whereas ownership types typically impose a geometric structure 
%% on references over the whole heap, a group of recent approaches have 
%% focussed on a local view of the sharing or accessibility of objects.
%
the Alias
Calculus \cite{meyer-alias-calculus-scp2015,meyer-auto-alias-sncs2020},
Reachability
Types \cite{romf-reachability-types-oopsla2021,rompf-poly-reachability-oopsla2024}
and Capturing
Types \cite{odersky-capturing-types-toplas2023,scoped-effects-oopsla2022,odersky-reach-prog2024}
abstract fine grained method-level descriptions of how
references and aliases flow into and out of methods, fields,
and object instances. While these approaches do not directly
expresss protection, 
they likely accumulate all the information required to support it.
%in one or more of these frameworks could be fruitful future work.


%%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% 
%%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% %%%% 
